{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE Predictions based on Mutlivariate Gauassian\n",
    "Notebook to create and evaluate baseline model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import create_dataloaders\n",
    "from utils.evaluation import visualise_batch_predictions\n",
    "import torch\n",
    "\n",
    "from config import config\n",
    "\n",
    "DATA_PATH = config.PATH_TO_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [0, 1, 2, 3,]\n",
    "train_loader, val_loader, test_loader = create_dataloaders(DATA_PATH, bands=bands, batch_size=2000, transforms=False) # get full train and val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_in, y_in):\n",
    "    X_out = torch.permute(X_in, (1, 0, 2, 3)).flatten(start_dim=1).T\n",
    "    y_out = y_in.flatten(start_dim=0)\n",
    "\n",
    "    assert X_out.shape[0] == len(y_out)\n",
    "    print(\"Dimensions of transformed output: \")\n",
    "    print(\"Data: {}\".format(X_out.shape))\n",
    "    print(\"Labels: {}\".format(y_out.shape))\n",
    "    return X_out, y_out\n",
    "\n",
    "def pull_train_loader(loader, n_pulls):\n",
    "    image_batches = []\n",
    "    mask_batches = []\n",
    "    for _ in range(n_pulls):\n",
    "        batch_x, batch_y = next(iter(loader))\n",
    "        image_batches.append(batch_x)\n",
    "        mask_batches.append(batch_y)\n",
    "\n",
    "    X = torch.cat(image_batches, 0)\n",
    "    y = torch.cat(mask_batches, 0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all data from image loaders\n",
    "X_train, y_train = pull_train_loader(train_loader, 1)\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "X_val, y_val = next(iter(val_loader))\n",
    "\n",
    "# print dimensions\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# flatten all data\n",
    "X_train, y_train = prepare_data(X_train, y_train)\n",
    "X_test, y_test = prepare_data(X_test, y_test)\n",
    "X_val, y_val = prepare_data(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MLE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLE_model():\n",
    "    def __init__(self, ):\n",
    "        self.pos_means = None\n",
    "        self.neg_means = None\n",
    "        self.pos_cov = None\n",
    "        self.neg_cov = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        # seperate data into both classes\n",
    "        pos = (y_train==1)\n",
    "        neg = (y_train==0)\n",
    "\n",
    "        X_train_pos = X_train[pos, :]\n",
    "        X_train_neg = X_train[neg, :]\n",
    "\n",
    "        # fit multivariate gaussian distributions for both classes\n",
    "        self.pos_means = torch.mean(X_train_pos, dim=0).numpy()\n",
    "        self.pos_cov = np.cov(X_train_pos.numpy().T)\n",
    "\n",
    "        self.neg_means = torch.mean(X_train_neg, dim=0).numpy()\n",
    "        self.neg_cov = np.cov(X_train_neg.numpy().T)\n",
    "\n",
    "        # validate fitting process\n",
    "        print(\"Model Fitted with means {} and {}\".format(self.pos_means, self.neg_means))\n",
    "        print(\"Covariance matrix are \\n {} \\n and \\n {}\".format(self.pos_cov, self.neg_cov))\n",
    "        return\n",
    "\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        # convert to numpy\n",
    "        X_test = X_test.numpy()\n",
    "\n",
    "        # Run MLE estimator\n",
    "        # calculate log odds for both classes\n",
    "        log_ps = [self.compute_log_p_solution(X_test, m, s) for m, s in zip([self.neg_means, self.pos_means], [self.neg_cov, self.pos_cov])]\n",
    "        \n",
    "        # take argmax\n",
    "        assignments = np.argmax(log_ps, axis=0)\n",
    "        return log_ps, assignments\n",
    "    \n",
    "    def compute_log_p_solution(self, X, mean, sigma):\n",
    "        # Solution inspired by CS-433 Machine Learning exercises\n",
    "        d = X.shape[1]\n",
    "        c = -np.log(2 * np.pi) * (d / 2) - 0.5 * np.log(np.linalg.det(sigma))\n",
    "        A = X - mean\n",
    "        invSigma = np.linalg.inv(sigma)\n",
    "\n",
    "        return -0.5 * np.sum(A * (A.dot(invSigma)), axis=1) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit MLE model\n",
    "model = MLE_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_MLE(y_test, y_pred):\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_neg = 0\n",
    "    false_pos = 0\n",
    "\n",
    "    target = torch.tensor(y_test, dtype=torch.int64)\n",
    "    pred = torch.tensor(y_pred, dtype=torch.int64)\n",
    "\n",
    "    true_pos += ((target == 1) & (pred == 1)).sum().item()\n",
    "    true_neg += ((target == 0) & (pred == 0)).sum().item()\n",
    "    false_neg += ((target == 1) & (pred == 0)).sum().item()\n",
    "    false_pos += ((target == 0) & (pred == 1)).sum().item()\n",
    "\n",
    "    # Calculate metrics (on GPU if needed)\n",
    "    accuracy = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "    precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "    recall = true_pos / (true_pos + false_neg) if (true_pos + false_pos) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    jaccard = true_pos / (true_pos + false_neg + false_pos) if (true_pos + false_neg + false_pos) else 0\n",
    "\n",
    "    print(\"Accuracy: {:.4}\".format(accuracy))\n",
    "    print(\"F1: {:.4}\".format(f1))\n",
    "    print(\"Jaccard: {:.4}\".format(jaccard))\n",
    "    print(\"Precision: {:.4}\".format(precision))\n",
    "    print(\"Recall: {:.4}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and evaluate on the test set\n",
    "log_ps, pred_tot = model.predict(X_test)\n",
    "evaluate_MLE(y_test, pred_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and evaluate on the val set\n",
    "log_ps, pred_tot = model.predict(X_val)\n",
    "evaluate_MLE(y_val, pred_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Predictions\n",
    "visually, the MLE predictions are convincing too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload right sized image\n",
    "_, _, test_loader = create_dataloaders(DATA_PATH, bands=bands, batch_size=8, transforms=False) # get full train and val dataset\n",
    "loader = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_batch(model, batch_sample):\n",
    "    input = torch.permute(batch_sample, (1, 0, 2, 3)).flatten(start_dim=1).T\n",
    "    _, batch_output = model.predict(input)\n",
    "    batch_predictions = torch.tensor(batch_output).reshape(batch_sample.shape[0], 1, 128, 128)\n",
    "    return batch_predictions\n",
    "\n",
    "batch_sample, batch_mask = next(loader)\n",
    "batch_predictions = predict_from_batch(model, batch_sample)\n",
    "visualise_batch_predictions(batch_sample, batch_mask.unsqueeze(1), batch_predictions, rescale=True, bands=bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing unsupervised methods for good measure\n",
    "This seems to work equally well - we can approximate the two mutlivariate gaussians with the EM algorithm quite succesfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "model = GaussianMixture(n_components=2, verbose=True)\n",
    "\n",
    "n_samples = 10_000_000 # take a susample to speed up training\n",
    "indices = np.random.choice(np.arange(n_samples), size=n_samples)\n",
    "\n",
    "X_train_ = X_train[indices, :]\n",
    "\n",
    "model.fit(X_train_)\n",
    "\n",
    "print(\"Found means: \", model.means_)\n",
    "print(\"Found covariances: \", model.covariances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and evaluate on the test set\n",
    "pred_tot = model.predict(X_test)\n",
    "\n",
    "# since this is unspervised, we need to flip the class (if accuracy on your machine is bad, just flip it back by uncommenting)\n",
    "# pred_tot = np.where(pred_tot==1, 0, 1)\n",
    "\n",
    "evaluate_MLE(y_test, pred_tot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_deforestation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
