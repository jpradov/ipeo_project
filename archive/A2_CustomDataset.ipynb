{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.data as data\n",
    "from utils.visualisation import visualise_image\n",
    "from config import config\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "device = config.device\n",
    "DATA_PATH = config.PATH_TO_DATA\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.PlanetDataset(data_dir=DATA_PATH, bands=[0,1,2,3])\n",
    "print(dataset)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False, sampler=None,\n",
    "           batch_sampler=None, num_workers=0)\n",
    "\n",
    "dataloader = iter(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Example : loading data samples from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, mask = next(dataloader)\n",
    "print(type(sample))\n",
    "print(f\"Batch sample shape (batch, x, y, n_channels): {sample.shape}\")\n",
    "print(f\"Batch mask shape (batch, x, y): {mask.shape}\")\n",
    "visualise_image(sample[0].squeeze().numpy(),mask[0].squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Choosing framework to implement transforms/data augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option 1 : torchgeo + Kornia\n",
    "import torch\n",
    "\n",
    "### ATTENTION : this framework requires that sample tensors are of shape (batch, n_channels, x, y)\n",
    "# Doc: https://torchgeo.readthedocs.io/en/latest/tutorials/transforms.html\n",
    "# https://torchgeo.readthedocs.io/en/latest/api/transforms.html\n",
    "# \n",
    "sample = torch.permute(sample,(0,3,1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.transforms import v2\n",
    "import kornia.augmentation as K\n",
    "from torchgeo.transforms import AugmentationSequential, indices\n",
    "transforms = AugmentationSequential(\n",
    "    indices.AppendNDVI(index_nir=3, index_red=0), #There are very handy torchgeo functions for calculating indices!\n",
    "    K.RandomHorizontalFlip(p=1),\n",
    "    K.RandomVerticalFlip(p=1),\n",
    "    K.RandomBoxBlur(kernel_size=(10, 10), border_type='reflect', normalized=True, p=1), #Note that the randomblur is applied to the image but no the mask!\n",
    "    data_keys=[\"image\",\"mask\"],\n",
    ")\n",
    "transformed_tuple = transforms({\"image\" : sample, \"mask\" : mask})\n",
    "\n",
    "# Unshuffle dimensions of sample so it is compatible with Luca's visualize_image:\n",
    "\n",
    "transformed_tuple['image'] = torch.permute(transformed_tuple['image'],(0,2,3,1))\n",
    "\n",
    "visualise_image(transformed_tuple['image'][0].squeeze().numpy(),transformed_tuple['mask'][0].squeeze().numpy())\n",
    "\n",
    "print(f\"Note that we have a new channel corresponding to NDVI: {transformed_tuple['image'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, mask = next(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option 2 : torch transforms v2 (implemented in beta since March 2023)\n",
    "dataset = data.PlanetDataset(data_dir=DATA_PATH, bands=[0,1,2,3])\n",
    "print(dataset)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, sampler=None,\n",
    "           batch_sampler=None, num_workers=0)\n",
    "\n",
    "dataloader = iter(dataloader)\n",
    "\n",
    "sample, mask = next(dataloader)\n",
    "print(type(sample))\n",
    "print(f\"Batch sample shape (batch, x, y, n_channels): {sample.shape}\")\n",
    "print(f\"Batch mask shape (batch, x, y): {mask.shape}\")\n",
    "\n",
    "# get means for normlization\n",
    "means = torch.mean(sample.float(), dim=(0, 2, 3))\n",
    "stds = torch.std(sample.float(), dim=(0, 2, 3))\n",
    "\n",
    "visualise_image(sample[0].squeeze().numpy(),mask[0].squeeze().numpy())\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import kornia.augmentation as K\n",
    "from torchgeo.transforms import AugmentationSequential, indices\n",
    "\n",
    "print(sample.shape)\n",
    "sample = torch.permute(sample,(0,3,1,2))\n",
    "print(sample.shape)\n",
    "\n",
    "# get means for normlization\n",
    "means = torch.mean(sample.float(), dim=(0, 2, 3))\n",
    "stds = torch.std(sample.float(), dim=(0, 2, 3))\n",
    "\n",
    "sample = sample.float()\n",
    "\n",
    "transforms = AugmentationSequential(\n",
    "    K.Resize((224, 224)),\n",
    "    K.RandomResizedCrop(size=(224, 224), p=0.5),\n",
    "\n",
    "    K.RandomHorizontalFlip(p=0.5),\n",
    "    K.RandomVerticalFlip(p=0.5),\n",
    "    K.RandomBoxBlur(kernel_size=(10, 10), border_type='reflect', normalized=True, p=0.5), #Note that the randomblur is applied to the image but no the mask!\n",
    "    \n",
    "    # K.RandomGrayscale(p=1), only works when we have 3 input channels\n",
    "    # K.ColorJitter(p=1), only works when we have 3 input channels\n",
    "    # K.RandomPosterize(bits=4, p=1), # is a bit funky, need to normalize first\n",
    "    # K.RandomGaussianBlur(kernel_size=(3, 3), sigma=(0.1, 0.1), p=0.2), # duplicate from \n",
    "    #TODO: normalize\n",
    "    K.Normalize(mean=means, std=stds),\n",
    "\n",
    "    data_keys=[\"image\",\"mask\"],\n",
    ")\n",
    "\n",
    "\n",
    "transformed_tuple = transforms({\"image\" : sample, \"mask\" : mask})\n",
    "transformed_tuple['image'] = torch.permute(transformed_tuple['image'],(0,2,3,1))\n",
    "visualise_image(transformed_tuple['image'][0].squeeze().numpy(),transformed_tuple['mask'][0].squeeze().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option 2 : torch transforms v2 (implemented in beta since March 2023)\n",
    "### Old Experiments with Base Kornia - currently used in production\n",
    "\n",
    "from utils.visualisation import visualise_image_3_channels\n",
    "\n",
    "dataset = data.PlanetDataset(data_dir=DATA_PATH, bands=[0,1,2])\n",
    "print(dataset)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, sampler=None,\n",
    "           batch_sampler=None, num_workers=0)\n",
    "\n",
    "dataloader = iter(dataloader)\n",
    "\n",
    "sample, mask = next(dataloader)\n",
    "print(type(sample))\n",
    "print(f\"Batch sample shape (batch, x, y, n_channels): {sample.shape}\")\n",
    "print(f\"Batch mask shape (batch, x, y): {mask.shape}\")\n",
    "\n",
    "# get means for normlization\n",
    "means = torch.mean(sample.float(), dim=(0, 2, 3))\n",
    "stds = torch.std(sample.float(), dim=(0, 2, 3))\n",
    "\n",
    "visualise_image_3_channels(sample[0].squeeze().numpy(),mask[0].squeeze().numpy())\n",
    "\n",
    "\n",
    "print(sample.shape)\n",
    "sample = torch.permute(sample,(0,3,1,2))\n",
    "print(sample.shape)\n",
    "\n",
    "# get means for normlization\n",
    "means = torch.mean(sample.float(), dim=(0, 2, 3))\n",
    "stds = torch.std(sample.float(), dim=(0, 2, 3))\n",
    "\n",
    "sample = sample.float()\n",
    "mask = mask.float()\n",
    "mask = mask[:, None, :, :]\n",
    "print(mask.shape)\n",
    "\n",
    "\n",
    "transforms = K.container.AugmentationSequential(\n",
    "    K.Resize((224, 224)),\n",
    "    K.RandomResizedCrop(size=(224, 224), p=0.5),\n",
    "    K.RandomHorizontalFlip(p=0.5),\n",
    "    K.RandomVerticalFlip(p=0.5),\n",
    "    K.RandomBoxBlur(kernel_size=(20, 20), border_type='reflect', normalized=True, p=0.5), #Note that the randomblur is applied to the image but no the mask!\n",
    "    K.RandomGrayscale(p=0.2), # only works when we have 3 input channels\n",
    "    K.Normalize(mean=means, std=stds),\n",
    "    data_keys=[\"image\",\"mask\"],\n",
    ")\n",
    "\n",
    "transformed = transforms(sample, mask)\n",
    "transformed_tuple = {k: v for k, v in zip([\"image\", \"mask\"], transformed)}\n",
    "visualise_image_3_channels(transformed_tuple['image'][0].squeeze().numpy(),transformed_tuple['mask'][0].squeeze().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
